{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Read Datasets & PII Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviornment for developing a quick method to scan through datasets and see what PPID and PID are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = 'data/chicagoParole.csv'\n",
    "loc2 = 'data/Strategic_Subject_List_-_Historical_20240320.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pii_violation(csv_filePath: str, pii_roots = ['Name', 'Date', 'Time', 'Address', 'Residence', 'County', 'State', 'District', 'Street', 'Code', 'Number', 'Age', 'Ethnicity', 'Gender', 'Occupation', 'Status', 'DOB', 'Year', 'Month', 'Day']):\n",
    "    # read in the CSV\n",
    "    data = pd.read_csv(csv_filePath)  \n",
    "\n",
    "    # create a lowercase version of whatever was passed in or the default list\n",
    "    pii_roots = [x.lower() for x in pii_roots] \n",
    "\n",
    "    # container for the hit columns\n",
    "    suspected_pii = []\n",
    "\n",
    "    # check each of the columns against our pii_roots (the default or a custom one)\n",
    "    for col in data.columns:\n",
    "        # make sure everything is the same regardless of casing\n",
    "        lowercol = col.lower()\n",
    "\n",
    "        # check the lower case versions, but append the normal column\n",
    "        if len(set(lowercol.split(' ')).intersection(pii_roots)) > 0:\n",
    "            # the roots matched, so the column(s) have a space as a delimiter\n",
    "            suspected_pii.append(col)\n",
    "\n",
    "        elif len(set(lowercol.split('_')).intersection(pii_roots)) > 0:\n",
    "            # the roots matched, so the column(s) have '_' as a delimiter\n",
    "            suspected_pii.append(col)\n",
    "        elif len(set(lowercol.split('-')).intersection(pii_roots)) > 0:\n",
    "            # the roots matched, so the column(s) have '-' as a delimiter\n",
    "            suspected_pii.append(col)\n",
    "\n",
    "    # hits in comparison to the columns\n",
    "    hitRate = round(len(suspected_pii) / len(data.columns), 2)\n",
    "\n",
    "    return suspected_pii, hitRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class\n",
    "\n",
    "Upgrades the function into something more robuts and useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIIScan():\n",
    "    def __init__(self, filePath: str, pii = ['Name', 'Date', 'Time', 'Address', 'Street', 'Residence', 'Country', 'County', 'State', 'District', 'Code', 'Number', 'Age', 'Ethnicity', 'Gender', 'Occupation', 'Status', 'DOB', 'Year', 'Month', 'Day']):\n",
    "        '''\n",
    "        Reads a dataset (csv or xlsx supported) given a filepath, saves it and the metadata, and checks for partial or complete PII matches.\n",
    "\n",
    "        Inputs:\n",
    "            - (str) filePath: the relative or full path to the CSV or XLSX file\n",
    "            - (list-like) pii: optional list of custom key words that we want to locate in the dataset features that may be PII. Default provided.\n",
    "\n",
    "        Returns:\n",
    "            - None. All information is saved to the object.\n",
    "\n",
    "        Attributes Defined Here:\n",
    "            - (str) filePath: The relative or full path to the data that was provided\n",
    "            - (str) fileName: The name of the file minus the extension\n",
    "            - (str) fileExtension: The extension name like 'csv' or 'xlsx'\n",
    "            - (list: str) features: All column (feature) names\n",
    "            - (list: str) roots: All key words that we assume are associated with PII (default provided)\n",
    "\n",
    "        Attributes Defined Elsewhere:\n",
    "            - (pd.DataFrame) df: Data stored in DataFrame format\n",
    "            - (list: str) matches: List of unique column (feature) names that were found to be partial or complete matches to something in the PII list\n",
    "            - (float) hitRate: Proportion of possibly PII columns in the dataset. Rounded to 2 decimal places)\n",
    "            - (pd.Series) nan: Feature name and proportion of it's entries that are NAN\n",
    "        '''\n",
    "        \n",
    "        # save the file path, name, and extension (mainly for report purposes)\n",
    "        self.filePath = filePath\n",
    "        self.fileName = Path(filePath).stem\n",
    "        self.fileExtension = filePath.split('.')[-1]\n",
    "\n",
    "        # get and save the data\n",
    "        self._readFile()\n",
    "        self.features = list(self.df.columns)\n",
    "\n",
    "        # save the lowercase version of roots passed in or used from default\n",
    "        self.roots = [root.lower() for root in pii]\n",
    "\n",
    "        # check for PII hits\n",
    "        print('Checking for PII Violations...')\n",
    "        self._piiViolation()\n",
    "\n",
    "        print('Reporting...\\n')\n",
    "\n",
    "        print(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f' File: {self.fileName} \\n File Type: {self.fileExtension} \\n Features: {len(self.features)} \\n Records: {len(self.df)} \\n\\n Possible PII Matches: {len(self.matches)} \\n Hit Rate: {self.hitRate} \\n\\n Possible Matches: {self.matches} '\n",
    "\n",
    "    def _readFile(self):\n",
    "        '''\n",
    "        Reads the datafile into a pandas DataFrame. Used in the initialization of the object.\n",
    "\n",
    "        Inputs:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - None\n",
    "\n",
    "        Attributes Defined Here:\n",
    "            - (pd.DataFrame) df: Data stored in DataFrame format\n",
    "            - (pd.Series) nan: Feature name and proportion of it's entries that are NAN\n",
    "        '''\n",
    "        \n",
    "        if self.fileExtension == 'csv':\n",
    "            print('Reading CSV...')\n",
    "        \n",
    "            self.df = pd.read_csv(self.filePath)\n",
    "        \n",
    "        elif self.fileExtension == 'xlsx':\n",
    "            print('Reading XLSX...')\n",
    "\n",
    "            self.df = pd.read_excel(self.filePath)\n",
    "        \n",
    "        else:\n",
    "            print(f'Extension not recognized: {self.fileExtension}')\n",
    "\n",
    "        # Feature NAN analysis (what proportion of the feature is NAN?)\n",
    "        print('Running feature NAN Analysis...')\n",
    "        self.nan = self.df.isna().mean()\n",
    "        \n",
    "    def _piiViolation(self):\n",
    "        '''\n",
    "        Runs the PII-matching method. Given the pandas representation of the data, look at the columns (features) and record the ones that contain the PII keywords we defined.\n",
    "\n",
    "        Inputs:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - None\n",
    "\n",
    "        Attributes Defined Here:\n",
    "            - (list: str) matches: List of unique column (feature) names that were found to be partial or complete matches to something in the PII list\n",
    "            - (float) hitRate: Proportion of possibly PII columns in the dataset. Rounded to 2 decimal places)\n",
    "        '''\n",
    "                \n",
    "        # container for the hit columns\n",
    "        suspected_pii = []\n",
    "\n",
    "        # check each of the columns against our pii_roots (the default or a custom one)\n",
    "        for col in self.features:\n",
    "            # make sure everything is the same regardless of casing\n",
    "            lowercol = col.lower()\n",
    "\n",
    "            # check the lower case versions, but append the normal column\n",
    "            if len(set(lowercol.split(' ')).intersection(self.roots)) > 0:\n",
    "                # the roots matched, so the column(s) have a space as a delimiter\n",
    "                suspected_pii.append(col)\n",
    "\n",
    "            elif len(set(lowercol.split('_')).intersection(self.roots)) > 0:\n",
    "                # the roots matched, so the column(s) have '_' as a delimiter\n",
    "                suspected_pii.append(col)\n",
    "\n",
    "            elif len(set(lowercol.split('-')).intersection(self.roots)) > 0:\n",
    "                # the roots matched, so the column(s) have '-' as a delimiter\n",
    "                suspected_pii.append(col)\n",
    "\n",
    "        # get rid of any duplicates we've amassed and save it\n",
    "        self.matches = list(np.unique(suspected_pii))\n",
    "        self.hitRate = round(len(suspected_pii) / len(self.features), 2)\n",
    "\n",
    "    def getData(self):\n",
    "        '''\n",
    "        Getter for the dataframe and the possible PII matches. \n",
    "\n",
    "        Inputs:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - (pd.DataFrame) df: Data stored in DataFrame format\n",
    "            - (list: str) matches: List of unique column (feature) names that were found to be partial or complete matches to something in the PII list\n",
    "        '''\n",
    "        return self.df, self.matches\n",
    "    \n",
    "    def getMatchSet(self):\n",
    "        '''\n",
    "        Getter for the auto-subset df of the possible matches.\n",
    "\n",
    "        Inputs:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - (pd.DataFrame): Subset data stored in DataFrame format\n",
    "        '''\n",
    "        return self.df[self.matches]\n",
    "    \n",
    "    def getMatchSet_Latex(self, rows = 5):\n",
    "        '''\n",
    "        Getter for the auto-subset df of the possible matches, but in latex format.\n",
    "\n",
    "        Inputs:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - (str): Latex tabular representation of the head of the data\n",
    "        '''\n",
    "        return print(self.df[self.matches].head(rows).to_latex(index = False))\n",
    "    \n",
    "    def getNan(self):\n",
    "        '''\n",
    "        Returns the columns that have some number of NANs in them.\n",
    "\n",
    "        Inputs:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - (pd.Series): Column (feature) names that have a proportion of NANs that greater than 0\n",
    "        '''\n",
    "\n",
    "        return self.nan[self.nan > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV...\n",
      "Running feature NAN Analysis...\n",
      "Checking for PII Violations...\n",
      "Reporting...\n",
      "\n",
      " File: chicagoParole \n",
      " File Type: csv \n",
      " Features: 30 \n",
      " Records: 15630 \n",
      "\n",
      " Possible PII Matches: 12 \n",
      " Hit Rate: 0.4 \n",
      "\n",
      " Possible Matches: ['Age', 'County of Residence', 'Current Admission Date', 'Custody Date', 'Date of Birth', 'MSR/Parole Date', 'Name', 'Projected Discharge Date', 'Residence Zip Code', 'Sentence Date', 'Sentencing County', 'Veteran Status'] \n"
     ]
    }
   ],
   "source": [
    "# default roots\n",
    "chicagoParole = PIIScan('data/chicagoParole.csv')\n",
    "# print(chicagoParole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Projected Discharge Date    0.097057\n",
       "Latitude                    0.001663\n",
       "Longitude                   0.001663\n",
       "New Offense Category        0.001599\n",
       "Years Until Discharge       0.097057\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicagoParole.getNan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>County of Residence</th>\n",
       "      <th>Current Admission Date</th>\n",
       "      <th>Custody Date</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>MSR/Parole Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Projected Discharge Date</th>\n",
       "      <th>Residence Zip Code</th>\n",
       "      <th>Sentence Date</th>\n",
       "      <th>Sentencing County</th>\n",
       "      <th>Veteran Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1997-09-12 00:00:00</td>\n",
       "      <td>1995-03-18 00:00:00</td>\n",
       "      <td>1952-04-20 00:00:00</td>\n",
       "      <td>2022-08-05 00:00:00</td>\n",
       "      <td>JONES, ROBERT</td>\n",
       "      <td>2025-08-05 00:00:00</td>\n",
       "      <td>60608</td>\n",
       "      <td>1997-09-08 00:00:00</td>\n",
       "      <td>Cook</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Winnebago</td>\n",
       "      <td>2020-09-02 00:00:00</td>\n",
       "      <td>2020-02-20 00:00:00</td>\n",
       "      <td>1954-09-09 00:00:00</td>\n",
       "      <td>2021-02-19 00:00:00</td>\n",
       "      <td>FOOTE, RAYMOND R.</td>\n",
       "      <td>2025-02-20 00:00:00</td>\n",
       "      <td>61102</td>\n",
       "      <td>2020-07-31 00:00:00</td>\n",
       "      <td>Winnebago</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Cook</td>\n",
       "      <td>2000-04-04 00:00:00</td>\n",
       "      <td>1998-09-02 00:00:00</td>\n",
       "      <td>1953-11-06 00:00:00</td>\n",
       "      <td>2022-10-11 00:00:00</td>\n",
       "      <td>ROGERS, CHARLES</td>\n",
       "      <td>2025-10-11 00:00:00</td>\n",
       "      <td>60445</td>\n",
       "      <td>2000-03-27 00:00:00</td>\n",
       "      <td>Cook</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>Cook</td>\n",
       "      <td>2019-01-11 00:00:00</td>\n",
       "      <td>2018-06-09 00:00:00</td>\n",
       "      <td>1951-04-24 00:00:00</td>\n",
       "      <td>2023-04-21 00:00:00</td>\n",
       "      <td>FRENCH-SMITH, ALFRED</td>\n",
       "      <td>2026-04-23 00:00:00</td>\n",
       "      <td>60426</td>\n",
       "      <td>2019-01-09 00:00:00</td>\n",
       "      <td>Cook</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>Cook</td>\n",
       "      <td>2002-11-06 00:00:00</td>\n",
       "      <td>1982-04-09 00:00:00</td>\n",
       "      <td>1955-04-13 00:00:00</td>\n",
       "      <td>2021-11-30 00:00:00</td>\n",
       "      <td>COVELLI, ROBERT</td>\n",
       "      <td>2024-11-30 00:00:00</td>\n",
       "      <td>60660</td>\n",
       "      <td>2002-10-11 00:00:00</td>\n",
       "      <td>Dupage</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age County of Residence Current Admission Date         Custody Date  \\\n",
       "0   71                Cook    1997-09-12 00:00:00  1995-03-18 00:00:00   \n",
       "1   69           Winnebago    2020-09-02 00:00:00  2020-02-20 00:00:00   \n",
       "2   70                Cook    2000-04-04 00:00:00  1998-09-02 00:00:00   \n",
       "3   72                Cook    2019-01-11 00:00:00  2018-06-09 00:00:00   \n",
       "4   68                Cook    2002-11-06 00:00:00  1982-04-09 00:00:00   \n",
       "\n",
       "         Date of Birth      MSR/Parole Date                  Name  \\\n",
       "0  1952-04-20 00:00:00  2022-08-05 00:00:00         JONES, ROBERT   \n",
       "1  1954-09-09 00:00:00  2021-02-19 00:00:00     FOOTE, RAYMOND R.   \n",
       "2  1953-11-06 00:00:00  2022-10-11 00:00:00       ROGERS, CHARLES   \n",
       "3  1951-04-24 00:00:00  2023-04-21 00:00:00  FRENCH-SMITH, ALFRED   \n",
       "4  1955-04-13 00:00:00  2021-11-30 00:00:00       COVELLI, ROBERT   \n",
       "\n",
       "  Projected Discharge Date  Residence Zip Code        Sentence Date  \\\n",
       "0      2025-08-05 00:00:00               60608  1997-09-08 00:00:00   \n",
       "1      2025-02-20 00:00:00               61102  2020-07-31 00:00:00   \n",
       "2      2025-10-11 00:00:00               60445  2000-03-27 00:00:00   \n",
       "3      2026-04-23 00:00:00               60426  2019-01-09 00:00:00   \n",
       "4      2024-11-30 00:00:00               60660  2002-10-11 00:00:00   \n",
       "\n",
       "  Sentencing County Veteran Status  \n",
       "0              Cook             No  \n",
       "1         Winnebago             No  \n",
       "2              Cook             No  \n",
       "3              Cook             No  \n",
       "4            Dupage             No  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicagoParole.getMatchSet().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rlllllllrlll}\n",
      "\\toprule\n",
      "Age & County of Residence & Current Admission Date & Custody Date & Date of Birth & MSR/Parole Date & Name & Projected Discharge Date & Residence Zip Code & Sentence Date & Sentencing County & Veteran Status \\\\\n",
      "\\midrule\n",
      "71 & Cook & 1997-09-12 00:00:00 & 1995-03-18 00:00:00 & 1952-04-20 00:00:00 & 2022-08-05 00:00:00 & JONES, ROBERT & 2025-08-05 00:00:00 & 60608 & 1997-09-08 00:00:00 & Cook & No \\\\\n",
      "69 & Winnebago & 2020-09-02 00:00:00 & 2020-02-20 00:00:00 & 1954-09-09 00:00:00 & 2021-02-19 00:00:00 & FOOTE, RAYMOND R. & 2025-02-20 00:00:00 & 61102 & 2020-07-31 00:00:00 & Winnebago & No \\\\\n",
      "70 & Cook & 2000-04-04 00:00:00 & 1998-09-02 00:00:00 & 1953-11-06 00:00:00 & 2022-10-11 00:00:00 & ROGERS, CHARLES & 2025-10-11 00:00:00 & 60445 & 2000-03-27 00:00:00 & Cook & No \\\\\n",
      "72 & Cook & 2019-01-11 00:00:00 & 2018-06-09 00:00:00 & 1951-04-24 00:00:00 & 2023-04-21 00:00:00 & FRENCH-SMITH, ALFRED & 2026-04-23 00:00:00 & 60426 & 2019-01-09 00:00:00 & Cook & No \\\\\n",
      "68 & Cook & 2002-11-06 00:00:00 & 1982-04-09 00:00:00 & 1955-04-13 00:00:00 & 2021-11-30 00:00:00 & COVELLI, ROBERT & 2024-11-30 00:00:00 & 60660 & 2002-10-11 00:00:00 & Dupage & No \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(chicagoParole.getMatchSet().head().to_latex())\n",
    "chicagoParole.getMatchSet_Latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chicago parole dataframe and possible matches\n",
    "cpdf, cppm = chicagoParole.getData()\n",
    "\n",
    "# commenting this line out because it shows real names\n",
    "# cpdf[cppm].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/s4dmzgv113lb3_sdwwd28tv40000gn/T/ipykernel_5442/2745220228.py:68: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df = pd.read_csv(self.filePath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature NAN Analysis...\n",
      "Checking for PII Violations...\n",
      "Reporting...\n",
      "\n",
      " File: Strategic_Subject_List_-_Historical_20240320 \n",
      " File Type: csv \n",
      " Features: 48 \n",
      " Records: 398684 \n",
      "\n",
      " Possible PII Matches: 15 \n",
      " Hit Rate: 0.31 \n",
      "\n",
      " Possible Matches: ['AGE CURR', 'AGE GROUP', 'AGE TO', 'IDOC RES STATE CODE', 'IDOC RES ZIP CODE', 'LATEST DATE', 'LATEST DOMESTIC ARR DATE', 'LATEST NARCOTIC ARR DATE', 'LATEST WEAPON ARR DATE', 'PREDICTOR RAT AGE AT LATEST ARREST', 'RACE CODE CD', 'SEX CODE CD', 'SSL LAST PTV DATE', 'STATUS I', 'TRAP STATUS'] \n"
     ]
    }
   ],
   "source": [
    "other = PIIScan(loc2)\n",
    "# print(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other dataframe and possible matches\n",
    "otherdf, otherpm = other.getData()\n",
    "\n",
    "# otherdf[otherpm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREDICTOR RAT AGE AT LATEST ARREST    0.000256\n",
       "AGE GROUP                             0.000384\n",
       "AGE TO                                0.000384\n",
       "STOP ORDER NO                         0.995844\n",
       "PAROLEE I                             0.967182\n",
       "MAJORITY DIST                         0.366240\n",
       "DLST                                  0.852113\n",
       "WEAPONS ARR CNT                       0.951974\n",
       "LATEST WEAPON ARR DATE                0.951974\n",
       "NARCOTICS ARR CNT                     0.767217\n",
       "LATEST NARCOTIC ARR DATE              0.767217\n",
       "IDOC RES CITY                         0.852156\n",
       "IDOC RES STATE CODE                   0.852151\n",
       "IDOC RES ZIP CODE                     0.853852\n",
       "IDOC CPD DIST                         0.971852\n",
       "DOMESTIC ARR CNT                      0.829123\n",
       "LATEST DOMESTIC ARR DATE              0.829123\n",
       "AGE CURR                              0.000604\n",
       "SSL LAST PTV DATE                     0.964398\n",
       "TRAP STATUS                           0.992179\n",
       "TRAP FLAGS                            0.999737\n",
       "SSL FLAGS                             0.998876\n",
       "LATITUDE                              0.437562\n",
       "LONGITUDE                             0.437562\n",
       "CENSUS TRACT                          0.428713\n",
       "LOCATION                              0.437562\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other.getNan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading XLSX...\n",
      "Running feature NAN Analysis...\n",
      "Checking for PII Violations...\n",
      "Reporting...\n",
      "\n",
      " File: Parole pop subset \n",
      " File Type: xlsx \n",
      " Features: 30 \n",
      " Records: 15630 \n",
      "\n",
      " Possible PII Matches: 12 \n",
      " Hit Rate: 0.4 \n",
      "\n",
      " Possible Matches: ['Age', 'County of Residence', 'Current Admission Date', 'Custody Date', 'Date of Birth', 'MSR/Parole Date', 'Name', 'Projected Discharge Date', 'Residence Zip Code', 'Sentence Date', 'Sentencing County', 'Veteran Status'] \n"
     ]
    }
   ],
   "source": [
    "largeParoleData = PIIScan('data/Parole pop subset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Projected Discharge Date    0.097057\n",
       "Latitude                    0.001663\n",
       "Longitude                   0.001663\n",
       "New Offense Category        0.001599\n",
       "Years Until Discharge       0.097057\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largeParoleData.getNan()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
